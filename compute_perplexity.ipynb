{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOn9FtPcSAu/R9S3TYpgKm/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Savoxism/AI-Text-Detection-Model/blob/main/compute_perplexity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHyAc4yp29id"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub\n",
        "!pip install safetensors\n",
        "!pip install tokenizers sentencepiece sacremoses importlib_metadata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "# Import the AutoModelWithLMHead class\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "# Define the model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
        "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'gpt2')\n",
        "\n",
        "# Define the texts\n",
        "generated_text = \"The sun was shining brightly in the sky. It was a beautiful day to go for a walk. I put on my shoes and grabbed my phone. I decided to listen to some music while I walked. I opened Spotify and searched for my favorite playlist. I pressed play and put on my headphones. I felt a surge of happiness as the first song started playing. It was one of my favorite songs ever. I smiled and started walking.\"\n",
        "human_text = \"I love sunny days. They make me feel so happy and energetic. I decided to take advantage of the nice weather and go for a walk. I put on my sneakers and took my phone with me. I wanted to listen to some music while I enjoyed the fresh air. I opened Spotify and looked for a playlist that matched my mood. I found one that had a lot of upbeat songs. I hit play and put on my earbuds. The first song that came on was perfect. It was one of those songs that always makes me smile. I started walking with a spring in my step.\"\n",
        "\n",
        "# Define a function to calculate perplexity\n",
        "def perplexity(text, model, tokenizer):\n",
        "  # Encode the text\n",
        "  input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "  # Get the logits from the model\n",
        "  logits = model(input_ids).logits\n",
        "  # Get the probabilities from the logits using softmax\n",
        "  probs = F.softmax(logits, dim=-1)\n",
        "  # Get the log probabilities from the probabilities using log_softmax\n",
        "  log_probs = F.log_softmax(logits, dim=-1)\n",
        "  # Multiply the probabilities and the log probabilities element-wise\n",
        "  p_log_p = probs * log_probs\n",
        "  # Sum up the p_log_p values along the last dimension\n",
        "  p_log_p_sum = torch.sum(p_log_p, dim=-1)\n",
        "  # Negate the p_log_p_sum values\n",
        "  neg_p_log_p_sum = -p_log_p_sum\n",
        "  # Take the mean of the neg_p_log_p_sum values\n",
        "  mean_neg_p_log_p_sum = torch.mean(neg_p_log_p_sum)\n",
        "  # Exponentiate the mean_neg_p_log_p_sum value to get the perplexity\n",
        "  perplexity = math.exp(mean_neg_p_log_p_sum)\n",
        "  # Return the perplexity\n",
        "  return perplexity\n",
        "\n",
        "# Calculate the perplexities of the texts\n",
        "generated_text_perplexity = perplexity(generated_text, model, tokenizer)\n",
        "human_text_perplexity = perplexity(human_text, model, tokenizer)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Generated text perplexity: {generated_text_perplexity}\")\n",
        "print(f\"Human text perplexity: {human_text_perplexity}\")"
      ],
      "metadata": {
        "id": "qOsexZMy3WLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"In addition, in 2015, the number of total visitors came to approximately about 2.75 million and the number of people who chose not to go on the island exceeded their island counterparts. In the following years, there was not a significant change in the figure of total visitors; however, the number of people who chose to stay on ships was slightly higher than on the island with the number of 1.5 million. Additionally, both figures saw a sharp increase to 2 million and 1.5 million which are also the highest rate of the two numbers in the period.\""
      ],
      "metadata": {
        "id": "dnXBQnil3xcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text_perplexity = perplexity(input_text, model, tokenizer)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Input text perplexity: {input_text_perplexity}\")"
      ],
      "metadata": {
        "id": "x6lvrIrz6nOL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}